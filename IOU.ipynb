{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongminkim0501/Image_deep/blob/main/IOU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjftD-dElhzV",
        "outputId": "c6aee740-404e-4354-d99a-9d9ffe84add0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0roR92ymEQv",
        "outputId": "7f87f32e-9651-4fd9-e227-1e12a1bb0bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data_ai/train_buildings_image\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/data_ai/train_buildings_image/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8wDC4ZA_mLAJ"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/data_ai/\"\n",
        "json_path = \"/content/drive/MyDrive/data_ai/train_buildings_labels\"\n",
        "original_path = \"/content/drive/MyDrive/data_ai/train_buildings_image\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "acZD3d_DmMoj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "82cfced4-7631-499b-c591-31f7f2ea0d84"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4036fdaaaef5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_fill_cache\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "json_load1 = []\n",
        "img1 = []\n",
        "\n",
        "import os\n",
        "dataset_path = \"/content/drive/MyDrive/data_ai/\"\n",
        "png_list = os.listdir(json_path)\n",
        "\n",
        "for i in range (len(png_list)):\n",
        "  png_list[i] = png_list[i].split(\".\")\n",
        "\n",
        "png_t = []\n",
        "for i in range (len(png_list)):\n",
        "  if len(png_list[i]) == 2 and png_list[i][1] == 'json':\n",
        "    png_t.append(png_list[i][0])\n",
        "\n",
        "for item in png_t:\n",
        "  img = np.zeros((1024, 1024, 3), np.uint8)\n",
        "\n",
        "  with open(json_path+f\"/{item}.json\") as json_file:\n",
        "    json_load = json.load(json_file)\n",
        "    json.dumps(json_load, indent='\\t')\n",
        "  for number in range(len(json_load[\"features\"])):\n",
        "    vv = json_load[\"features\"][number][\"properties\"][\"building_imcoords\"]\n",
        "    a = vv.split(\", \")\n",
        "\n",
        "    pts = []\n",
        "    for i in range(0,int(len(a)/2)):\n",
        "      vvv = []\n",
        "      vvv.append(float(a[2*i]))\n",
        "      vvv.append(float(a[2*i+1]))\n",
        "      pts.append(vvv)\n",
        "\n",
        "    for i in range(0,int(len(a)/2)):\n",
        "      for j in range(2):\n",
        "        pts[i][j] = int(pts[i][j])\n",
        "    pts = np.array(pts)\n",
        "    img = cv2.fillPoly(img, [pts],(255,255,255))\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/data_ai/json_images_building/{item}.png', img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import json\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "json_load1 = []\n",
        "img1 = []\n",
        "\n",
        "import os\n",
        "dataset_path = \"/content/drive/MyDrive/data_ai/\"\n",
        "png_list = os.listdir(json_path)\n",
        "\n",
        "for i in range (len(png_list)):\n",
        "  png_list[i] = png_list[i].split(\".\")\n",
        "\n",
        "png_t = []\n",
        "for i in range (len(png_list)):\n",
        "  if len(png_list[i]) == 2 and png_list[i][1] == 'json':\n",
        "    png_t.append(png_list[i][0])\n",
        "\n",
        "k = copy.deepcopy(png_t[:200])\n",
        "png_t = None"
      ],
      "metadata": {
        "id": "4K1ez8gXOhqb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Q_oJ2Bo4mwM5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "label_image_black_white = []\n",
        "label_origin_image = []\n",
        "\n",
        "for name in k:\n",
        "\n",
        "  img = cv2.imread(f\"/content/drive/MyDrive/data_ai/json_images_building/{name}.png\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  lab = cv2.imread(f\"/content/drive/MyDrive/data_ai/train_buildings_image/{name}.png\")\n",
        "\n",
        "  if np.array(img).shape[0] != 1024 or np.array(lab).shape[0] != 1024:\n",
        "    continue\n",
        "\n",
        "  img = cv2.resize(img, (256, 256))\n",
        "  lab = cv2.resize(lab, (256, 256))\n",
        "  label_image_black_white.append(img)\n",
        "  label_origin_image.append(lab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in label_origin_image:\n",
        "  print(item.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhVBeXguZXoE",
        "outputId": "9e023e44-7351-456b-ed6d-52d551fad93b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bXxv0HcEm0TZ"
      },
      "outputs": [],
      "source": [
        "x_test = []\n",
        "x_train = []\n",
        "\n",
        "y_test = []\n",
        "y_train = []\n",
        "import os\n",
        "dataset_path = \"/content/drive/MyDrive/data_ai/\"\n",
        "# png_list = os.listdir(\"/content/drive/MyDrive/data_ai/train_buildings_labels/\")\n",
        "# for i in range (len(png_list)):\n",
        "#   png_list[i] = png_list[i].split(\".\")\n",
        "# png_t = []\n",
        "# for i in range (len(png_list)):\n",
        "#   if len(png_list[i]) == 2 and png_list[i][1] == 'json':\n",
        "#     png_t.append(png_list[i][0])\n",
        "\n",
        "for i in range(0, round(len(k)*0.8)):\n",
        "  x_train.append(label_origin_image[i])\n",
        "  y_train.append(label_image_black_white[i])\n",
        "\n",
        "for i in range(round(len(k)*0.8), len(k)):\n",
        "  x_test.append(label_origin_image[i])\n",
        "  y_test.append(label_image_black_white[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(label_image_black_white)):\n",
        "  print(label_image_black_white[i].shape)\n",
        "  print(y_train)\n",
        "# for i in range (len(x_test)):\n",
        "#   print(x_train[i].shape)\n",
        "#   print(x_test[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csvyg6UqadLN",
        "outputId": "217f8093-9797-4c3f-97da-ede3d1a9dbac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n",
            "(256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GJEmHEhem1SM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "5afac58f-8344-4ed5-b0e3-8de6d2624e2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-51dab9764d41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# def attention_gate(input_signal, gating_signal, num_filters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     # gating_signal을 input_signal과 같은 크기로 조정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_KerasLazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mself_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# incompatibilities before we trigger them (which would typically result in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# SIGILL).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_cpu_feature_guard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0m_pywrap_cpu_feature_guard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInfoAboutUnusedCPUFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, Add, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import L2\n",
        "# def attention_gate(input_signal, gating_signal, num_filters):\n",
        "#     # gating_signal을 input_signal과 같은 크기로 조정\n",
        "#     gating_signal = Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(gating_signal)\n",
        "\n",
        "#     # 1x1 convolution\n",
        "#     input_signal = Conv2D(num_filters, 1, padding='same')(input_signal)\n",
        "#     gating_signal = Conv2D(num_filters, 1, padding='same')(gating_signal)\n",
        "\n",
        "#     # 신호 결합\n",
        "#     added = Add()([input_signal, gating_signal])\n",
        "\n",
        "#     # 활성화\n",
        "#     activated = Activation('relu')(added)\n",
        "\n",
        "#     # attention 계수 계산\n",
        "#     attention = Conv2D(1, 1, padding='same')(activated)\n",
        "#     attention = Activation('sigmoid')(attention)\n",
        "\n",
        "#     # attention 적용\n",
        "#     return Multiply()([input_signal, attention])\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    # attended_skip = attention_gate(skip_features, input, num_filters)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    # x = Concatenate()([x, attended_skip])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    size = 8     # ORiginal: 16\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, size * 4)\n",
        "    s2, p2 = encoder_block(p1, size * 8)\n",
        "    s3, p3 = encoder_block(p2, size * 16)\n",
        "    s4, p4 = encoder_block(p3, size * 32)\n",
        "\n",
        "    b1 = conv_block(p4, size * 64)    # Original is 1024\n",
        "\n",
        "    d1 = decoder_block(b1, s4, size * 32)\n",
        "    d2 = decoder_block(d1, s3, size * 16)\n",
        "    d3 = decoder_block(d2, s2, size * 8)\n",
        "    d4 = decoder_block(d3, s1, size * 4)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhXQbJ3hUII2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zfc9ZHGi3Wkw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "7494aa01-7786-437f-f6ea-bd56f90fdf7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntf.keras.layers.BatchNormalization(\\n    axis=-1, : 정규화할 축을 지정, -1은 마지막 축 (채널)을 의미. channels_last 포맷에서는 -1이 적절\\n    momentum=0.99, : 이동 평균을 계산할 때 사용되는 모멘텀. 0~1사이 값, 큰 값: 이전 통계를 더 많이 반영,\\n                      작은 값 : 새로운 배치 통계를 더 많이 반영\\n    epsilon=0.001, : 분모가 0이 되는 것을 방지하기 위한 작은 상수, 수치적 안정성을 위해 사용\\n    center=True,: beta 오프셋 사용 여부, True면 평균을 이동 시킴, false 면 스케일이 1로 고정\\n    scale=True, : gamma 스케일링 사용 여부, True면 스케일 조정 가능, false 면 스케일이 1로 고정\\n    beta_initializer='zeros', : beta 벡터의 초기화 방법\\n    gamma_initializer='ones', : gamma 벡터의 초기화 방법\\n    moving_mean_initializer='zeros', : 이동 평균의 초기화 방법\\n    moving_variance_initializer='ones', : 이동 분산의 초기화 방법\\n    beta_regularizer=None, : beta 파라미터에 대한 정규화 함수\\n    gamma_regularizer=None, : gamma 파라미터에 대한 정규화 함수\\n    beta_constraint=None, : beta 파라미터에 대한 제약\\n    gamma_constraint=None, : gamma 파라미터에 대한 제약\\n    synchronized=False, : 분산 학습에 배치 정규화를 동기화 할 지 여부 / 여러 gpu 사용시 관\\n    **kwargs\\n)\\nintersection over union\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "'''\n",
        "tf.keras.layers.Conv2D(\n",
        "    filters, : 출력 채널의 수, filters = 32 이면, 32개의 특성 맵 생성\n",
        "    kernel_size, : 컨볼루션 윈도의 크기, kernel size=3 : 3x3 필터\n",
        "    strides=(1, 1), : 필터가 이동하는 간격\n",
        "    padding='valid', : valid - 패딩 없음, same : 출력 크기와 입력 크기 동일하도록 패딩\n",
        "    data_format=None, :\n",
        "    dilation_rate=(1, 1), : 팽창된 컨볼루션을 위한 팽창률, (1,1) - 일반 컨볼루션, (2,2) - 필터 원소 사이에 공간 추가\n",
        "    groups=1, : 입력과 출력 채널을 그룹으로 나누는 수, 1은 일반적인 컨볼루션, groups > 1 은 채널 그룹 분리\n",
        "    activation=None, : 활성화 함수, relu, sigmoid 등, none : 선형 활성화\n",
        "    use_bias=True, : 편향 벡터의 사용 여부\n",
        "    kernel_initializer='glorot_uniform', : 커널 가중치 초기화 방법\n",
        "    bias_initializer='zeros', : 편향 가중치 초기화 방법, zeros, ones\n",
        "    kernel_regularizer=None, : 커널 가중치에 대한 정규화 함수, l1, l2\n",
        "    bias_regularizer=None, : 편향에 대한 정규화 함수\n",
        "    activity_regularizer=None, : 출력에 대한 정규화 함수\n",
        "    kernel_constraint=None, : 커널 가중치에 대한 제약, max_norm 등\n",
        "    bias_constraint=None, : 편향에 대한 제약\n",
        "    **kwargs\n",
        ")\n",
        "'''\n",
        "'''\n",
        "tf.keras.layers.BatchNormalization(\n",
        "    axis=-1, : 정규화할 축을 지정, -1은 마지막 축 (채널)을 의미. channels_last 포맷에서는 -1이 적절\n",
        "    momentum=0.99, : 이동 평균을 계산할 때 사용되는 모멘텀. 0~1사이 값, 큰 값: 이전 통계를 더 많이 반영,\n",
        "                      작은 값 : 새로운 배치 통계를 더 많이 반영\n",
        "    epsilon=0.001, : 분모가 0이 되는 것을 방지하기 위한 작은 상수, 수치적 안정성을 위해 사용\n",
        "    center=True,: beta 오프셋 사용 여부, True면 평균을 이동 시킴, false 면 스케일이 1로 고정\n",
        "    scale=True, : gamma 스케일링 사용 여부, True면 스케일 조정 가능, false 면 스케일이 1로 고정\n",
        "    beta_initializer='zeros', : beta 벡터의 초기화 방법\n",
        "    gamma_initializer='ones', : gamma 벡터의 초기화 방법\n",
        "    moving_mean_initializer='zeros', : 이동 평균의 초기화 방법\n",
        "    moving_variance_initializer='ones', : 이동 분산의 초기화 방법\n",
        "    beta_regularizer=None, : beta 파라미터에 대한 정규화 함수\n",
        "    gamma_regularizer=None, : gamma 파라미터에 대한 정규화 함수\n",
        "    beta_constraint=None, : beta 파라미터에 대한 제약\n",
        "    gamma_constraint=None, : gamma 파라미터에 대한 제약\n",
        "    synchronized=False, : 분산 학습에 배치 정규화를 동기화 할 지 여부 / 여러 gpu 사용시 관\n",
        "    **kwargs\n",
        ")\n",
        "intersection over union\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aIeO4ZMm2Ip"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_train /= 255.0\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_train /= 255.0\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_test /= 255.0\n",
        "y_test = y_test.astype(np.float32)\n",
        "y_test /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_simple_model(input_shape=(256, 256, 3)):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)  # (batch_size, 256, 256, 3)\n",
        "\n",
        "    # Single conv layer to change only the number of channels (3 -> 1)\n",
        "    # Kernel size = 1 means it only changes channels, preserves spatial dimensions\n",
        "    outputs = Conv2D(\n",
        "        filters=1,                     # Output channels = 1\n",
        "        kernel_size=1,                 # 1x1 convolution\n",
        "        padding='same',                # Preserve spatial dimensions\n",
        "        activation='sigmoid'           # For binary output\n",
        "    )(inputs)                         # (batch_size, 256, 256, 1)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"Simple-Shape-Model\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "n5iPCrtqTQjq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "JDQDaqovpd-5",
        "outputId": "ca42fadf-17f9-4ea3-e776-157d3fe46c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"Simple-Shape-Model\" is incompatible with the layer: expected shape=(None, 256, 256, 3), found shape=(32, 1024, 1024, 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-eb7a2255dcca>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           metrics=['accuracy'])\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"Simple-Shape-Model\" is incompatible with the layer: expected shape=(None, 256, 256, 3), found shape=(32, 1024, 1024, 3)"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import asyncio\n",
        "model = build_simple_model((256,256,3))\n",
        "# model = build_unet((256, 256, 3))\n",
        "optimizer = Adam(learning_rate = 0.1)\n",
        "model.compile(optimizer=optimizer,\n",
        "          loss=tf.losses.BinaryCrossentropy(),\n",
        "          metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScKQ04utAA3N"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img1 = np.array(x_test[5])\n",
        "print(img1)\n",
        "res = model.predict(np.expand_dims(img1, axis = 0)) * 255 # predicted image , over 0.5 -> 255,\n",
        "print(res.shape)\n",
        "img2 = np.array(y_test[5])\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.imshow(cv2.cvtColor(res[0], cv2.COLOR_GRAY2BGR))\n",
        "ax1.set_title(\"predicted image\")\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "ax2.imshow(cv2.cvtColor(y_test[5], cv2.COLOR_BGR2RGB))\n",
        "ax2.set_title(\"correct image\")\n",
        "ax2.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "def iou(x,y):\n",
        "  x = x.flatten() #predict\n",
        "  print(x, len(x))\n",
        "  y = y.flatten() #answer\n",
        "  print(y, len(y))\n",
        "  tmp = [0 for _ in range (len(x))]\n",
        "  s = [0 for _ in range (len(x))]\n",
        "  for i in range(len(x)):\n",
        "    if x[i] >= 0.5:\n",
        "      x[i] = 255\n",
        "    else:\n",
        "      x[i] = 0\n",
        "    if y[i] >= 0.5:\n",
        "      y[i] = 255\n",
        "    else:\n",
        "      y[i] = 0\n",
        "    if x[i] == 255 and y[i] == 255:\n",
        "      tmp[i] = 255 # same\n",
        "    elif x[i] == 255 and y[i] != 255:\n",
        "      s[i] = 255\n",
        "    elif x[i] != 255 and y[i] != 255:\n",
        "      s[i] = 255\n",
        "    else:\n",
        "      s[i] = 255\n",
        "  k = np.sum(s)\n",
        "  d = np.sum(tmp)\n",
        "  result = d / (k + d)\n",
        "  print(k, d, result)\n",
        "  return result\n",
        "\n",
        "x = iou(res, img2)\n",
        "print(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNsrAYxu5B2JBscyAC+PwtO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}